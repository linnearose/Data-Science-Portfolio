{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install regex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import regex as re\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read `.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in .csv files\n",
    "aww1 = pd.read_csv('./data/aww1.csv')\n",
    "aww2 = pd.read_csv('./data/aww2.csv')\n",
    "aww3 = pd.read_csv('./data/aww3.csv')\n",
    "aww4 = pd.read_csv('./data/aww4.csv')\n",
    "aww5 = pd.read_csv('./data/aww5.csv')\n",
    "\n",
    "ds1 = pd.read_csv('./data/ds1.csv')\n",
    "ds2 = pd.read_csv('./data/ds2.csv')\n",
    "ds3 = pd.read_csv('./data/ds3.csv')\n",
    "ds4 = pd.read_csv('./data/ds4.csv')\n",
    "\n",
    "cats1 = pd.read_csv('./data/cats1.csv')\n",
    "cats2 = pd.read_csv('./data/cats2.csv')\n",
    "cats3 = pd.read_csv('./data/cats3.csv')\n",
    "cats4 = pd.read_csv('./data/cats4.csv')\n",
    "\n",
    "dogs1 = pd.read_csv('./data/dogs1.csv')\n",
    "dogs2 = pd.read_csv('./data/dogs2.csv')\n",
    "dogs3 = pd.read_csv('./data/dogs3.csv')\n",
    "dogs4 = pd.read_csv('./data/dogs4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate .csv files into one DataFrame\n",
    "\n",
    "# # cats vs. dogs\n",
    "# df = pd.concat([cats1, cats2, cats3, dogs1, dogs2, dogs3])\n",
    "\n",
    "# cats vs. dogs vs. aww\n",
    "df = pd.concat([aww1, aww2, aww3, aww4, aww5, cats1, cats2, cats3, cats4, dogs1, dogs2, dogs3, dogs4])\n",
    "\n",
    "# # cats vs. dogs vs. aww vs. datascience\n",
    "# df = pd.concat([ds1, ds2, ds3, ds4, aww1, aww2, aww3, aww4, cats1, cats2, cats3, dogs1, dogs2, dogs3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0         0\n",
       "title              0\n",
       "subreddit          0\n",
       "name               0\n",
       "num_comments       0\n",
       "is_video           0\n",
       "pinned             0\n",
       "id                 0\n",
       "selftext        8151\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for nulls\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary column\n",
    "df.drop(['Unnamed: 0','selftext','num_comments','pinned'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset index\n",
    "df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>name</th>\n",
       "      <th>is_video</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>R/AWW OFFICIAL DISCORD!!! JOIN NOW!</td>\n",
       "      <td>aww</td>\n",
       "      <td>t3_97vuvt</td>\n",
       "      <td>False</td>\n",
       "      <td>97vuvt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>r/catsandchristmastrees: /r/Aww Subreddit of t...</td>\n",
       "      <td>aww</td>\n",
       "      <td>t3_a7yh12</td>\n",
       "      <td>False</td>\n",
       "      <td>a7yh12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sunset</td>\n",
       "      <td>aww</td>\n",
       "      <td>t3_a80fbf</td>\n",
       "      <td>False</td>\n",
       "      <td>a80fbf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bandit turned 25 years old on December 7th!</td>\n",
       "      <td>aww</td>\n",
       "      <td>t3_a814sv</td>\n",
       "      <td>False</td>\n",
       "      <td>a814sv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Looking good for 23!!</td>\n",
       "      <td>aww</td>\n",
       "      <td>t3_a7z8or</td>\n",
       "      <td>False</td>\n",
       "      <td>a7z8or</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title subreddit       name  \\\n",
       "0                R/AWW OFFICIAL DISCORD!!! JOIN NOW!       aww  t3_97vuvt   \n",
       "1  r/catsandchristmastrees: /r/Aww Subreddit of t...       aww  t3_a7yh12   \n",
       "2                                             sunset       aww  t3_a80fbf   \n",
       "3        Bandit turned 25 years old on December 7th!       aww  t3_a814sv   \n",
       "4                              Looking good for 23!!       aww  t3_a7z8or   \n",
       "\n",
       "   is_video      id  \n",
       "0     False  97vuvt  \n",
       "1     False  a7yh12  \n",
       "2     False  a80fbf  \n",
       "3     False  a814sv  \n",
       "4     False  a7z8or  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identify and remove duplicate rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11961"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9328"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(df['name']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates = df.duplicated(subset='name',\n",
    "                          keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, duplicates], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={0:'duplicate'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redefine df as df without duplicates\n",
    "df = df[df['duplicate'] == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset index\n",
    "df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9328"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check all rows\n",
    "len(df['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9328"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that all rows are unique\n",
    "len(set(df['name']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "765"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check how many are videos\n",
    "video = df[df['is_video'] == True]\n",
    "len(video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many videos are datascience\n",
    "len(video[video['subreddit'] == 'datascience'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many videos are dogs\n",
    "len(video[video['subreddit'] == 'dogs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "201"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many videos are cats\n",
    "len(video[video['subreddit'] == 'cats'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "564"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many videos are aww\n",
    "len(video[video['subreddit'] == 'aww'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis\n",
    "\n",
    "**As mentioned in the modeling analysis ahead**, there were many `aww` posts that were predicted incorrectly as `cats`. I think that adding in another independent variable like `is_video` could improve the accuracy of my model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+', gaps=False)\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning subreddit titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access each title individually\n",
    "titles = [df.iloc[i][0] for i in range(len(df))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['R/AWW OFFICIAL DISCORD!!! JOIN NOW!',\n",
       " 'r/catsandchristmastrees: /r/Aww Subreddit of the Week!',\n",
       " 'sunset']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_num(titles):\n",
    "    for i in range(len(titles)):\n",
    "        titles[i] = re.sub('[^\\D]+', '', titles[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "strip_num(titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['R/AWW OFFICIAL DISCORD!!! JOIN NOW!',\n",
       " 'r/catsandchristmastrees: /r/Aww Subreddit of the Week!',\n",
       " 'sunset']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenize titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(titles):\n",
    "    for i in range(len(titles)):\n",
    "        titles[i] = tokenizer.tokenize(titles[i].lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize(titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['r', 'aww', 'official', 'discord', 'join', 'now'],\n",
       " ['r', 'catsandchristmastrees', 'r', 'aww', 'subreddit', 'of', 'the', 'week'],\n",
       " ['sunset']]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove stop words\n",
    "def stop_words(titles):\n",
    "    for i in range(len(titles)):\n",
    "        raw_words = titles[i]\n",
    "        titles[i] = [w for w in raw_words if not w in stopwords.words('english')]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words(titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['r', 'aww', 'official', 'discord', 'join'],\n",
       " ['r', 'catsandchristmastrees', 'r', 'aww', 'subreddit', 'week'],\n",
       " ['sunset']]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lemmatize ALL tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatize tokens\n",
    "list2 = []\n",
    "def lemm(titles):\n",
    "    for x in range(len(titles)):\n",
    "        list1 = []\n",
    "        for i in titles[x]:\n",
    "            list1.append(lemmatizer.lemmatize(i))\n",
    "        list2.append(list1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemm(titles)\n",
    "titles = list2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['r', 'aww', 'official', 'discord', 'join'],\n",
       " ['r', 'catsandchristmastrees', 'r', 'aww', 'subreddit', 'week'],\n",
       " ['sunset']]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis\n",
    "\n",
    "Now that the remaining words have been lemmatized, we're left with more stripped-down versions of words that still had unnecessary morphemes attached. What this means is that now words that are orthographically different that have the same meanings won't be processed as different words.\n",
    "\n",
    "In this example, lemmatizing these three words will result in three instances of the *same* word.\n",
    "\n",
    " - computer --> compute\n",
    " - computerize --> compute\n",
    " - compute --> compute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Join strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(titles)):\n",
    "    titles[i] = ' '.join(titles[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['r aww official discord join',\n",
       " 'r catsandchristmastrees r aww subreddit week',\n",
       " 'sunset',\n",
       " 'bandit turned year old december th',\n",
       " 'looking good']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Put into DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty DataFrame\n",
    "clean_title = pd.DataFrame(index=range(len(titles)), \n",
    "                           columns=['clean_title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input clean titles into empty DataFrame\n",
    "for i in range(len(titles)):\n",
    "    clean_title.iloc[i] = titles[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine clean_title DataFrame and original DataFrame \n",
    "df['clean_title'] = clean_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>name</th>\n",
       "      <th>is_video</th>\n",
       "      <th>id</th>\n",
       "      <th>duplicate</th>\n",
       "      <th>clean_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>R/AWW OFFICIAL DISCORD!!! JOIN NOW!</td>\n",
       "      <td>aww</td>\n",
       "      <td>t3_97vuvt</td>\n",
       "      <td>False</td>\n",
       "      <td>97vuvt</td>\n",
       "      <td>False</td>\n",
       "      <td>r aww official discord join</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>r/catsandchristmastrees: /r/Aww Subreddit of t...</td>\n",
       "      <td>aww</td>\n",
       "      <td>t3_a7yh12</td>\n",
       "      <td>False</td>\n",
       "      <td>a7yh12</td>\n",
       "      <td>False</td>\n",
       "      <td>r catsandchristmastrees r aww subreddit week</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sunset</td>\n",
       "      <td>aww</td>\n",
       "      <td>t3_a80fbf</td>\n",
       "      <td>False</td>\n",
       "      <td>a80fbf</td>\n",
       "      <td>False</td>\n",
       "      <td>sunset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bandit turned 25 years old on December 7th!</td>\n",
       "      <td>aww</td>\n",
       "      <td>t3_a814sv</td>\n",
       "      <td>False</td>\n",
       "      <td>a814sv</td>\n",
       "      <td>False</td>\n",
       "      <td>bandit turned year old december th</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Looking good for 23!!</td>\n",
       "      <td>aww</td>\n",
       "      <td>t3_a7z8or</td>\n",
       "      <td>False</td>\n",
       "      <td>a7z8or</td>\n",
       "      <td>False</td>\n",
       "      <td>looking good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title subreddit       name  \\\n",
       "0                R/AWW OFFICIAL DISCORD!!! JOIN NOW!       aww  t3_97vuvt   \n",
       "1  r/catsandchristmastrees: /r/Aww Subreddit of t...       aww  t3_a7yh12   \n",
       "2                                             sunset       aww  t3_a80fbf   \n",
       "3        Bandit turned 25 years old on December 7th!       aww  t3_a814sv   \n",
       "4                              Looking good for 23!!       aww  t3_a7z8or   \n",
       "\n",
       "   is_video      id  duplicate                                   clean_title  \n",
       "0     False  97vuvt      False                   r aww official discord join  \n",
       "1     False  a7yh12      False  r catsandchristmastrees r aww subreddit week  \n",
       "2     False  a80fbf      False                                        sunset  \n",
       "3     False  a814sv      False            bandit turned year old december th  \n",
       "4     False  a7z8or      False                                  looking good  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save to .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('./data/animal_data')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
